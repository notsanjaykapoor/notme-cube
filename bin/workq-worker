#!/usr/bin/env python

import functools
import os
import random
import signal
import sys

sys.path.append(".")

import dot_init

import asyncio
import click
import ulid

import log
import models
import services.database
import services.nats
import services.workq


logger = log.init("api")

shutdown: bool = False

worker_me: dict = {}

def coro(f):
    @functools.wraps(f)
    def wrapper(*args, **kwargs):
        return asyncio.run(f(*args, **kwargs))

    return wrapper


@click.group()
def cli():
    pass


def signal_handler(signum, frame):
    global shutdown
    shutdown = True
    logger.info("[workq-worker] signal handler ... preparing to shutdown")


@click.command()
@click.option('--db-uri', default="", required=False, help="db uri string, e.g. postgresql://postgres:postgres@postgres-dev:5433/db_src")
@click.option('--queue', default=None, required=True, help="nats queue group name")
@click.option('--interval', default=5, required=False, help="sleep interval")
@click.option('--id', default="", required=False, help="worker id")
@click.option('--subject', default="workers", required=False, help="nats subject name")
@coro
async def run(db_uri: str, queue: str, interval: int, id: str, subject: str) -> dict:
    db_uri = db_uri or os.environ.get("DATABASE_URL")

    if not db_uri:
        raise ValueError("db_uri is invalid or missing")

    # install signal handler
    signal.signal(signal.SIGINT, signal_handler)

    if not services.workq.route(queue=queue):
        logger.error(f"[workq-worker] queue '{queue}' handler required")
        exit(1)

    worker_me["worker_id"] = id or ulid.new().str
    worker_me["worker_state"] = models.worker.STATE_IDLE

    worker_id = worker_me.get("worker_id")

    nats_name = f"worker-{worker_id}"
    nats_client = await services.nats.connect(name=nats_name)
    nats_client_id = nats_client.client_id

    logger.info(f"[workq-worker] {worker_id} queue '{queue}' client {nats_client_id} connected")

    _task = asyncio.create_task(
        pong_task(nats_client=nats_client, interval=15)
    )

    while not shutdown:
        # subscribe without a handler for a single message, wait and process message, and repeat
        nats_sub = await nats_client.subscribe(queue, subject)
        await nats_sub.unsubscribe(limit=1)

        logger.info(f"[workq-worker] {worker_id} queue '{queue}' nats subscribed '{subject}'")

        while not shutdown and nats_sub.pending_msgs == 0:
            await asyncio.sleep(interval)

        if shutdown:
            break

        async for msg in nats_sub.messages:
            msg_dict = services.nats.msg_decode(b=msg.data)
            job_id = msg_dict.get("job_id")

            with services.database.session.get() as db_session:
                job = services.workq.get_by_id(db_session=db_session, id=job_id)

                worker_me["worker_state"] = models.worker.STATE_BUSY

                logger.info(f"[workq-worker] {worker_id} queue '{queue}' job {job_id} processing")

                reply_dict = msg_dict | {"job_state":  models.workq.STATE_PROCESSING, "worker_id": worker_id}
                await msg.respond(services.nats.msg_encode(d = reply_dict))
                await nats_sub.drain()

                logger.info(f"[workq-worker] {worker_id} queue '{queue}' job {job_id} nats ack")

                try:
                    # process message
                    handler = services.workq.route(queue=queue)
                    await handler.call(db_session=db_session, job=job)

                    job_state = models.workq.STATE_COMPLETED

                    logger.info(f"[workq-worker] {worker_id} queue '{queue}' job {job_id} completed")
                except Exception as e:
                    job_state = models.workq.STATE_ERROR
                    logger.error(f"[workq-worker] {worker_id} queue '{queue}' job {job_id} exception {e}")

                reply_dict = msg_dict | {"job_state": job_state, "worker_id": worker_id}
                await nats_client.publish("workers.status", services.nats.msg_encode(d = reply_dict))

                worker_me["worker_state"] = models.worker.STATE_IDLE

                # loop exits here since subscription was for 1 message

    logger.info(f"[workq-worker] {worker_id} queue '{queue}' client {nats_client_id} closing")

    await nats_client.publish("workers.shutdown", services.nats.msg_encode(d={"worker_id": worker_id}))
    await nats_client.drain()
    await nats_client.close()

    logger.info(f"[workq-worker] {worker_id} queue '{queue}' client {nats_client_id} exiting")


async def pong_task(nats_client, interval: int):
    logger.info(f"[workq-worker] {worker_me.get('worker_id')} pong task starting")

    while True:
        if shutdown:
            break

        if random.randint(1, 100) < 10:
            logger.info(f"[workq-worker] {worker_me.get('worker_id')} pong publish")

        await nats_client.publish("workers.pong", services.nats.msg_encode(d=worker_me))
        await asyncio.sleep(interval)

    logger.info(f"[workq-worker] {worker_me.get('worker_id')} pong task exiting")

    
cli.add_command(run)

if __name__ == "__main__":
    asyncio.run(cli())