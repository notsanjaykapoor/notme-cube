#!/usr/bin/env python

import functools
import json
import os
import signal
import sys

sys.path.append(".")

import dot_init

import asyncio
import click
import nats
import ulid

import log
import services.database
import services.workq


logger = log.init("api")

shutdown: bool = False


def coro(f):
    @functools.wraps(f)
    def wrapper(*args, **kwargs):
        return asyncio.run(f(*args, **kwargs))

    return wrapper


@click.group()
def cli():
    pass


def signal_handler(signum, frame):
    global shutdown
    shutdown = True
    logger.info("workq worker signal handler ... preparing to shutdown")


@click.command()
@click.option('--db-uri', default="", required=False, help="db uri string, e.g. postgresql://postgres:postgres@postgres-dev:5433/db_src")
@click.option('--queue', default=None, required=True, help="work queue name")
@click.option('--interval', default=5, required=False, help="sleep interval")
@click.option('--id', default="", required=False, help="worker id")
@coro
async def run(db_uri: str, queue: str, interval: int, id: str) -> dict:
    db_uri = db_uri or os.environ.get("DATABASE_URL")

    if not db_uri:
        raise ValueError("db_uri is invalid or missing")

    # install signal handler
    signal.signal(signal.SIGINT, signal_handler)

    if not services.workq.route(queue=queue):
        logger.error(f"workq worker queue '{queue}' handler required")
        exit(1)

    worker_id = id or ulid.new().str

    nats_client = await nats.connect(os.environ.get("NATS_URI"))

    logger.info(f"workq worker '{worker_id}' queue '{queue}' nats client {nats_client.client_id}")

    _task = asyncio.create_task(
        pong_task(nats_client=nats_client, worker_id=worker_id, interval=15)
    )

    while not shutdown:
        # subscribe without a handler for a single message, wait and process message, and repeat
        nats_sub = await nats_client.subscribe(queue, "workers")
        await nats_sub.unsubscribe(limit=1)

        logger.info(f"workq worker '{worker_id}' queue '{queue}' nats poll")

        while not shutdown and nats_sub.pending_msgs == 0:
            await asyncio.sleep(interval)

        if shutdown:
            break

        async for msg in nats_sub.messages:
            msg_data_dict = json.loads(msg.data.decode())
            msg_id = msg_data_dict.get("id")

            with services.database.session.get() as db_session:
                workq = services.workq.get_by_id(db_session=db_session, id=msg_id)

                services.workq.state_processing(
                    db_session=db_session,
                    workq=workq,
                    worker=worker_id,
                )

                logger.info(f"workq worker '{worker_id}' queue '{queue}' message {workq.id} processing")

                respond_dict = msg_data_dict | {"worker": worker_id}
                await msg.respond(json.dumps(respond_dict).encode())
                await nats_sub.drain()

                logger.info(f"workq worker '{worker_id}' queue '{queue}' message {workq.id} nats ack")

                try:
                    # process message
                    handler = services.workq.route(queue=queue)
                    handler.call(db_session=db_session, workq=workq)

                    # update work object state
                    services.workq.state_completed(db_session=db_session, workq=workq)

                    logger.info(f"workq worker '{worker_id}' queue '{queue}' message {workq.id} completed")
                except Exception as e:
                    # update work object state
                    services.workq.state_error(db_session=db_session, workq=workq)
                    logger.error(f"workq worker '{worker_id}' queue '{queue}' message {workq.id} exception {e}")

                # loop exits here since we subscribed for 1 message

    logger.info(f"workq worker '{worker_id}' queue '{queue}' nats closing")

    await nats_client.publish("workers.shutdown", json.dumps({"worker": worker_id}).encode())
    await nats_client.drain()
    await nats_client.close()

    logger.info(f"workq worker '{worker_id}' queue '{queue}' exiting")


async def pong_task(nats_client, worker_id: str, interval: int):
    logger.info(f"workq worker '{worker_id}' pong task")

    pong_msg = {
        "worker": worker_id
    }

    while True:
        if shutdown:
            break
        await nats_client.publish("workers.pong", json.dumps(pong_msg).encode())
        await asyncio.sleep(interval)

    logger.info(f"workq worker '{worker_id}' pong task exiting")

    
cli.add_command(run)

if __name__ == "__main__":
    asyncio.run(cli())