#!/usr/bin/env python

import functools
import json
import os
import signal
import sys

sys.path.append(".")

import dot_init

import asyncio
import click
import nats

import log
import models
import services.database
import services.workq


logger = log.init("api")

shutdown: bool = False

def coro(f):
    @functools.wraps(f)
    def wrapper(*args, **kwargs):
        return asyncio.run(f(*args, **kwargs))

    return wrapper


@click.group()
def cli():
    pass


def signal_handler(signum, frame):
    global shutdown
    shutdown = True
    logger.info("workq scheduler signal handler ... preparing to shutdown")


@click.command()
@click.option('--db-uri', default="", required=False, help="db uri string, e.g. postgresql://postgres:postgres@postgres-dev:5433/db_src")
@click.option('--queue', default=None, required=True, help="work queue name")
@click.option('--interval', default=5, required=False, help="")
@coro
async def run(db_uri: str, queue: str, interval: int) -> dict:
    db_uri = db_uri or os.environ.get("DATABASE_URL")

    if not db_uri:
        raise ValueError("db_uri is invalid or missing")

    # install signal handler
    signal.signal(signal.SIGINT, signal_handler)

    with services.database.session.get() as db_session:
        cleanup_count = services.workq.cleanup(
            db_session=db_session,
            queue=queue,
            partition=-1,
        )

    logger.info(f"workq scheduler queue '{queue}' cleanup {cleanup_count}")

    nats_client = await nats.connect(os.environ.get("NATS_URI"))

    logger.info(f"workq scheduler queue '{queue}' nats client {nats_client.client_id}")

    while not shutdown:
        with services.database.session.get() as db_session:
            workq = services.workq.get_queued(
                db_session=db_session,
                queue=queue,
                partition=-1,
            )

            if not workq:
                logger.info(f"workq scheduler queue '{queue}' sleep {interval}")
                await asyncio.sleep(interval)
                continue

            logger.info(f"workq scheduler queue '{queue}' id {workq.id} request")

            await work_request(
                nats_client=nats_client,
                queue=queue,
                workq=workq,
                interval=interval,
            )

    logger.info(f"workq scheduler queue '{queue}' nats closing")

    await nats_client.close()

    logger.info(f"workq scheduler queue '{queue}' exiting")


async def work_request(nats_client, queue: str, workq: models.WorkQ, interval: int) -> int:
     while not shutdown:
        try:
            request_msg = {
                "id": workq.id
            }
            response = await nats_client.request(queue, json.dumps(request_msg).encode(), timeout=5)
            response_msg = response.data.decode()

            logger.info(f"workq scheduler queue '{queue}' id {workq.id} response {response_msg}")

            return 0
        except nats.errors.NoRespondersError as e:
            # no responders, either all workers are busy or there are no workers
            logger.error(f"nats error {e}")
        except nats.errors.TimeoutError as e:
            # timeouts should not happen
            logger.error(f"nats error {e}")

        await asyncio.sleep(interval)


cli.add_command(run)

if __name__ == "__main__":
    asyncio.run(cli())